{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1e3fb63",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------\n",
    "\n",
    "Copyright 2023 Benjamin Alexander Albert \\[Karchin Lab\\]\n",
    "\n",
    "All Rights Reserved\n",
    "\n",
    "BigMHC Academic License\n",
    "\n",
    "attention.ipynb\n",
    "\n",
    "------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48198c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "srcpath = os.path.abspath(\"../src\")\n",
    "if srcpath not in sys.path:\n",
    "    sys.path.append(srcpath)\n",
    "\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from mhcenc import MHCEncoder\n",
    "from dataset import Dataset\n",
    "from bigmhc import BigMHC\n",
    "from mhcuid import mhcuid\n",
    "\n",
    "datadir  = \"../data\"\n",
    "traindir = os.path.join(datadir, \"el_train\")\n",
    "\n",
    "print(\"making MHCEncoder...\", end=\"\")\n",
    "mhcenc = MHCEncoder.read(os.path.join(datadir, \"pseudoseqs.csv\"))\n",
    "print(\"done\")\n",
    "\n",
    "print(\"reading data...\", end=\"\")\n",
    "eltrain = pd.read_csv(os.path.join(datadir, \"out\", \"el_trainval.csv\"))\n",
    "eltest  = pd.read_csv(os.path.join(datadir, \"out\", \"el_test.csv\"))\n",
    "print(\"done\")\n",
    "\n",
    "print(\"loading model...\", end=\"\")\n",
    "models = [torch.nn.DataParallel(\n",
    "    BigMHC.load(\"../models/trainval/bat{}\".format(int(2**b))).to(0)) for b in range(9, 16)]\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc93a296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generated via https://colab.research.google.com/github/deepmind/alphafold/blob/main/notebooks/AlphaFold.ipynb on Jan. 3rd, 2023\n",
    "# >HLA-A*66:01\n",
    "# MAVMAPRTLVLLLSGALALTQTWAGSHSMRYFYTSVSRPGRGEPRFIAVGYVDDTQFVRFDSDAASQRMEPRAPWIEQEGPEYWDRNTRNVKAQSQTDRVDLGTLRG\n",
    "# YYNQSEDGSHTIQRMYGCDVGPDGRFLRGYQQDAYDGKDYIALNEDLRSWTAADMAAQITQRKWETAHEAEQWRAYLEGRCVEWLRRYLENGKETLQRTDAPKTHMT\n",
    "# HHAVSDHEATLRCWALSFYPAEITLTWQRDGEDQTQDTELVETRPAGDGTFQKWASVVVPSGQEQRYTCHVQHEGLPKPLTLRWEPSSQPTIPIVGIIAGLVLFGAV\n",
    "# IAGAVVAAVMWRRKSSDRKGGSYSQAASSDSAQGSDMSLTACKV\n",
    "\n",
    "# >HLA-B*40:01\n",
    "# MRVTAPRTVLLLLSAALALTETWAGSHSMRYFHTAMSRPGRGEPRFITVGYVDDTLFVRFDSDATSPRKEPRAPWIEQEGPEYWDRETQISKTNTQTYRESLRNLRG\n",
    "# YYNQSEAGSHTLQRMYGCDVGPDGRLLRGHNQYAYDGKDYIALNEDLRSWTAADTAAQISQRKLEAARVAEQLRAYLEGECVEWLRRYLENGKDKLERADPPKTHVT\n",
    "# HHPISDHEATLRCWALGFYPAEITLTWQRDGEDQTQDTELVETRPAGDRTFQKWAAVVVPSGEEQRYTCHVQHEGLPKPLTLRWEPSSQSTVPIVGIVAGLAVLAVV\n",
    "# VIGAVVAAVMCRRKSSGGKGGSYSQAACSDSAQGSDVSLTA\n",
    "\n",
    "# >HLA-C*08:02\n",
    "# MRVMAPRTLILLLSGALALTETWACSHSMRYFYTAVSRPGRGEPRFIAVGYVDDTQFVQFDSDAASPRGEPRAPWVEQEGPEYWDRETQKYKRQAQTDRVSLRNLRG\n",
    "# YYNQSEAGSHTLQRMYGCDLGPDGRLLRGYNQFAYDGKDYIALNEDLRSWTAADKAAQITQRKWEAAREAEQRRAYLEGTCVEWLRRYLENGKKTLQRAEHPKTHVT\n",
    "# HHPVSDHEATLRCWALGFYPAEITLTWQRDGEDQTQDTELVETRPAGDGTFQKWAAVVVPSGEEQRYTCHVQHEGLPEPLTLRWGPSSQPTIPIVGIVAGLAVLAVL\n",
    "# AVLGAVMAVVMCRRKSSGGKGGSCSQAASSNSAQGSDESLIACKA\n",
    "\n",
    "hlaA = \"HLAA6601\"\n",
    "hlaB = \"HLAB4001\"\n",
    "hlaC = \"HLAC0802\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d074bbd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getMHCMeanAttention(df):\n",
    "    tmpfp = \"cache/tmp.csv\"\n",
    "    df.iloc[:,1].to_csv(tmpfp, index=False, header=False)\n",
    "    pmhcs = Dataset.readPMHCs(\n",
    "        fp=tmpfp,\n",
    "        allele=df.iloc[0,0],\n",
    "        pepcol=0,\n",
    "        verbose=False)\n",
    "    dataset = Dataset(pmhcs=pmhcs, mhcenc=mhcenc)\n",
    "    dataset.makebats(maxbat=72000)\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=None,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        prefetch_factor=16)\n",
    "    attention = None\n",
    "    with torch.no_grad():\n",
    "        for idx,bat in enumerate(loader):\n",
    "            for m in models:\n",
    "                _, att = m(\n",
    "                    mhc=bat.mhc.to(0),\n",
    "                    pep=bat.pep.to(0))\n",
    "                att = torch.sum(att,dim=0).cpu()\n",
    "                if attention is None:\n",
    "                    attention = att\n",
    "                else:\n",
    "                    attention += att\n",
    "    return (attention / len(df) / len(models)).tolist()\n",
    "\n",
    "\n",
    "def getMeanAttention(df, cache):\n",
    "    if os.path.isfile(cache):\n",
    "        print(\"reading cache file {}...\".format(cache), end=\"\")\n",
    "        attention = pd.read_pickle(cache)\n",
    "        print(\"done\")\n",
    "    else:\n",
    "        if not os.path.exists(os.path.dirname(cache)):\n",
    "            os.makedirs(os.path.dirname(cache))\n",
    "        print(\"processing {} pMHC instances...\".format(len(df)))\n",
    "        alleles = sorted(df.iloc[:,0].unique())\n",
    "        attention = list()\n",
    "        for idx,mhc in enumerate(alleles):\n",
    "            print(\"  {}/{} {}...\".format(idx+1,len(alleles),mhc), end=\"\")\n",
    "            mhcdf = df[df.iloc[:,0]==mhc]\n",
    "            attention.append([mhc,0,getMHCMeanAttention(mhcdf[mhcdf.iloc[:,2]==0])])\n",
    "            attention.append([mhc,1,getMHCMeanAttention(mhcdf[mhcdf.iloc[:,2]==1])])\n",
    "            print(\"done\")\n",
    "        attention = pd.DataFrame(\n",
    "            columns=[\"mhc\",\"tgt\",\"att\"],\n",
    "            data=attention)\n",
    "        attention.to_pickle(cache)\n",
    "    return attention\n",
    "\n",
    "\n",
    "cacheMeanTrain = \"cache/el_mean_att_train.pkl\"\n",
    "cacheMeanTest  = \"cache/el_mean_att_test.pkl\"\n",
    "\n",
    "trainMeanAttention = getMeanAttention(eltrain, cacheMeanTrain)\n",
    "testMeanAttention  = getMeanAttention(eltest,  cacheMeanTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b193350",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def makeAttentionHeatmaps(df, attention, title):\n",
    "    \n",
    "    df.iloc[:,0] = df.iloc[:,0].apply(mhcuid)\n",
    "    attention[\"mhc\"] = attention[\"mhc\"].apply(mhcuid)\n",
    "    \n",
    "    neg = {'A':[], 'B':[], 'C':[]}\n",
    "    pos = {'A':[], 'B':[], 'C':[]}\n",
    "    dif = {'A':[], 'B':[], 'C':[]}\n",
    "    \n",
    "    alldiff = dict()\n",
    "    \n",
    "    yticklabels = {'A':[], 'B':[], 'C':[]}\n",
    "    \n",
    "    alleles = sorted(df.iloc[:,0].unique())\n",
    "\n",
    "    for mhc in alleles:\n",
    "        if not mhc.startswith(\"HLA\"):\n",
    "            continue\n",
    "        rows = attention[attention[\"mhc\"]==mhc]\n",
    "        N = torch.tensor(rows[rows[\"tgt\"]==0][\"att\"].iloc[0])\n",
    "        P = torch.tensor(rows[rows[\"tgt\"]==1][\"att\"].iloc[0])\n",
    "        D = P-N\n",
    "        alldiff[mhc] = D.tolist()\n",
    "\n",
    "        neg[mhc[3]].append(N.tolist())\n",
    "        pos[mhc[3]].append(P.tolist())\n",
    "        dif[mhc[3]].append(D.tolist())\n",
    "\n",
    "        yticklabels[mhc[3]].append(mhc[3:])\n",
    "\n",
    "    neg = {k:torch.tensor(v) for k,v in neg.items()}\n",
    "    pos = {k:torch.tensor(v) for k,v in pos.items()}\n",
    "    dif = {k:torch.tensor(v) for k,v in dif.items()}\n",
    "\n",
    "    absmax = {\n",
    "        x:torch.concat((neg[x],pos[x],dif[x]), dim=1).flatten().quantile(0.99)\n",
    "        for x in list(\"ABC\")}\n",
    "    absmax = {\n",
    "        x:max(absmax.values()) for x in list(\"ABC\")}\n",
    "\n",
    "    xticklabels = list()\n",
    "    for x in [x.split('_')[0] for x in mhcenc.cols]:\n",
    "        if len(xticklabels) and xticklabels[-1]==x:\n",
    "            continue\n",
    "        xticklabels.append(x)\n",
    "\n",
    "\n",
    "    sns.set_context(\"paper\")\n",
    "    style=\"whitegrid\"\n",
    "    rc={\"axes.facecolor\": \"0.99\",\n",
    "        \"grid.color\": \"0.95\",\n",
    "        \"axes.edgecolor\": \"0.90\"}\n",
    "\n",
    "    nA = len(yticklabels['A'])\n",
    "    nB = len(yticklabels['B'])\n",
    "    nC = len(yticklabels['C'])\n",
    "\n",
    "\n",
    "    with sns.axes_style(style=style, rc=rc):\n",
    "\n",
    "        heatmaps = plt.figure(figsize=(16,24*len(alleles)/149), dpi=600)\n",
    "        gs = heatmaps.add_gridspec(\n",
    "            nrows=3,\n",
    "            ncols=4,\n",
    "            wspace=0.02,\n",
    "            hspace=0.01,\n",
    "            width_ratios=[0.32,0.32,0.32,0.04],\n",
    "            height_ratios=[\n",
    "                nA / (nA+nB+nC),\n",
    "                nB / (nA+nB+nC),\n",
    "                nC / (nA+nB+nC)])\n",
    "        ax = gs.subplots()\n",
    "\n",
    "        mapdata = [pos, neg, dif]\n",
    "\n",
    "        for y,sup in enumerate(list(\"ABC\")):\n",
    "            for x,data in enumerate(mapdata):\n",
    "\n",
    "                sns.heatmap(\n",
    "                    data=data[sup],\n",
    "                    ax=ax[y][x],\n",
    "                    cmap=\"RdBu\",\n",
    "                    xticklabels=xticklabels,\n",
    "                    yticklabels=yticklabels[sup] if not x else [],\n",
    "                    vmin=-absmax[sup],\n",
    "                    vmax=absmax[sup],\n",
    "                    cbar_ax=ax[y][3])\n",
    "\n",
    "                if y==0:\n",
    "                    if x==0:\n",
    "                        ax[y][x].set_title(\"Positives\")\n",
    "                    elif x==1:\n",
    "                        ax[y][x].set_title(\"Negatives\")\n",
    "                    else:\n",
    "                        ax[y][x].set_title(\"Differences\")\n",
    "                if x==0:\n",
    "                    ax[y][x].set_ylabel(\"HLA-{}\".format(sup))\n",
    "                \n",
    "        heatmaps.suptitle(title, fontsize=20, y=0.91 if len(alleles)==149 else 1)\n",
    "    \n",
    "    return heatmaps, alldiff\n",
    "\n",
    "\n",
    "savedir = \"figs\"\n",
    "\n",
    "if not os.path.exists(savedir):\n",
    "    os.makedirs(savedir)\n",
    "\n",
    "trainmaps, trainmapsdif = makeAttentionHeatmaps(\n",
    "    df=eltrain,\n",
    "    attention=trainMeanAttention,\n",
    "    title=\"Weighted Mean Attention Values Across HLA Alleles in Training Data\")\n",
    "\n",
    "trainmaps.savefig(os.path.join(savedir,\"train_att_map.png\" ), bbox_inches=\"tight\")\n",
    "\n",
    "testmaps, testmapsdif = makeAttentionHeatmaps(\n",
    "    df=eltest,\n",
    "    attention=testMeanAttention,\n",
    "    title=\"Weighted Mean Attention Values Across HLA Alleles in Evaluation Data\")\n",
    "\n",
    "testmaps.savefig(os.path.join(savedir,\"test_att_map.png\" ), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61adb532",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import py3Dmol\n",
    "import matplotlib\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot3d(pdb, mapsdiff, mhc, q, absmax):\n",
    "    \n",
    "    mhc = mhcuid(mhc)\n",
    "    \n",
    "    att = getResAtt(mapsdiff, mhc)\n",
    "    \n",
    "    att = [(x+absmax) / (2*absmax) for x in att]\n",
    "    \n",
    "    with open(pdb) as f:\n",
    "        system = \"\".join([x for x in f])\n",
    "    \n",
    "    view = py3Dmol.view(width=600, height=600)\n",
    "    view.addModelsAsFrames(system)\n",
    "    \n",
    "    cmap = matplotlib.cm.get_cmap(\"cool_r\")\n",
    "    cmap = [(cmap(att[x]) if att[x] > -1 else (0.9,0.9,0.9)) for x in range(len(att))]\n",
    "    cmap = [\"#{:02X}{:02X}{:02X}\".format(\n",
    "        int(c[0]*255),\n",
    "        int(c[1]*255),\n",
    "        int(c[2]*255)) for c in cmap]\n",
    "    \n",
    "    for res in range(len(att)):\n",
    "        style = {\"cartoon\": {\"color\":cmap[res], \"arrows\":\"True\"}}\n",
    "        # if att[res] >= 0:\n",
    "        #     style[\"stick\"] = {}\n",
    "        view.setStyle({\"resi\":res+1}, style)\n",
    "    \n",
    "    view.zoomTo()\n",
    "    \n",
    "    alpha = 2*np.arccos(q[3])\n",
    "    sin = np.sin(alpha) / 2\n",
    "    x = q[0] / sin\n",
    "    y = q[1] / sin\n",
    "    z = q[2] / sin\n",
    "    norm = np.linalg.norm([x,y,z])\n",
    "    x /= norm\n",
    "    y /= norm\n",
    "    z /= norm\n",
    "    view.rotate(np.degrees(alpha), {'x':x,'y':y,'z':z})\n",
    "    \n",
    "    view.zoom(q[4])\n",
    "    \n",
    "    view.show()\n",
    "    \n",
    "    view.clim(-4,4)\n",
    "\n",
    "def getResAtt(att, mhc):\n",
    "    att = att[mhc]\n",
    "    res = (-1e9) * torch.ones(len(mhcenc[mhc]))\n",
    "    attidx = 0\n",
    "    for x in range(len(res)):\n",
    "        if mhcenc[mhc][x]:\n",
    "            col = int(mhcenc.cols[x].split('_')[0])\n",
    "            res[col] = att[attidx]\n",
    "            attidx += 1\n",
    "    return res.tolist()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "to get the viewer quaternion, first execute the following in the web console:\n",
    "\n",
    ">>  viewer = \"\"\n",
    "    for (var name in this)\n",
    "      if (name.startsWith(\"viewer_\"))\n",
    "        viewer = name\n",
    "    console.log(viewer)\n",
    "\n",
    "\n",
    "which will print the name of the most recent viewer, like this:\n",
    "    viewer_16548849854127703\n",
    "\n",
    "then, execute:\n",
    ">>  viewer_16548849854127703.getView()\n",
    "\n",
    "which will return an array of 8 elements, of which the last four can be\n",
    "copy/pasted as an argument to getResAtt as seen below,\n",
    "and the zoom can argument (q[4]) can be taken from the fourth element\n",
    "taken from the \n",
    "\n",
    "this can be used to manually rotate the view and then hardcode the\n",
    "quaternion to have replicatable viewing angles.\n",
    "\"\"\"\n",
    "\n",
    "hlaAatt = trainmapsdif[hlaA]\n",
    "hlaBatt = trainmapsdif[hlaB]\n",
    "hlaCatt = trainmapsdif[hlaC]\n",
    "\n",
    "minatt = min([*hlaAatt, *hlaBatt, *hlaCatt])\n",
    "maxatt = max([*hlaAatt, *hlaBatt, *hlaCatt])\n",
    "\n",
    "absmax = max(abs(minatt), abs(maxatt))\n",
    "\n",
    "plot3d(\"pdb/hlaa6601.pdb\", trainmapsdif, hlaA,\n",
    "       [0.01584834947434103, -0.9626169283722876, 0.18212611674386536, 0.19986884857285847, 2.4],\n",
    "        absmax)\n",
    "plot3d(\"pdb/hlab4001.pdb\", trainmapsdif, hlaB,\n",
    "       [0.14017763651136617, -0.9146756780073745, 0.2694812537241472, 0.26664299761122323, 2.5],\n",
    "        absmax)\n",
    "plot3d(\"pdb/hlac0802.pdb\", trainmapsdif, hlaC,\n",
    "       [0.004088738817461506, -0.9745425250220223, 0.1251330588426521, 0.18598888870915176, 2.5],\n",
    "        absmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb4b59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as pl\n",
    "\n",
    "    \n",
    "# Adapted from https://stackoverflow.com/a/16599889\n",
    "\n",
    "pl.figure(figsize=(1, 12), dpi=600)\n",
    "pl.imshow(np.array([[-absmax,absmax]]), cmap=\"cool_r\")\n",
    "pl.gca().set_visible(False)\n",
    "cax = pl.axes([0.1, 0.1, 0.5, 0.5])\n",
    "pl.colorbar(orientation=\"vertical\", cax=cax)\n",
    "pl.savefig(os.path.join(savedir, \"colorbar.png\"), facecolor=\"white\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
