{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e6aa510",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------\n",
    "\n",
    "Copyright 2023 Benjamin Alexander Albert \\[Karchin Lab\\]\n",
    "\n",
    "All Rights Reserved\n",
    "\n",
    "BigMHC Academic License\n",
    "\n",
    "makeseqs.ipynb\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "#### Generate MHC pseudosequences from FASTA files\n",
    "\n",
    "Create a dir, which we will call `data`\n",
    "  * Create a dir within `data` called `seq`\n",
    "    * Store all of the FASTA files and SAM alignment files the `seq` dir\n",
    "  * The final `pseudoseqs.csv`file will be placed in the `data` dir\n",
    "\n",
    "\n",
    "Three protein FASTA files are required as input:\n",
    "\n",
    "1. HLA FASTA file retrieved from: https://github.com/ANHIG/IMGTHLA\n",
    "   \n",
    "   Robinson J, Barker DJ, Georgiou X, Cooper MA, Flicek P, Marsh SG.\n",
    "   IPD-IMGT/HLA Database.\n",
    "   Nucleic acids research. 2020 Jan 8;48(D1):D948-55.\n",
    "   doi:10.1093/nar/gkz950\n",
    "\n",
    "   Robinson J, Malik A, Parham P, Bodmer JG, Marsh SG.\n",
    "   IMGT/HLA database: a sequence database for the human major histocompatibility complex.\n",
    "   Tissue antigens. 2000 Mar;55(3):280-7.\n",
    "   doi:10.1034/j.1399-0039.2000.550314.x\n",
    "\n",
    "   \n",
    "2. non-HLA MHC FASTA file retrieved from: https://github.com/ANHIG/IPDMHC\n",
    "\n",
    "   Robinson J, Halliwell JA, Hayhurst JD, Flicek P, Parham P, Marsh SG.\n",
    "   The IPD and IMGT/HLA database: allele variant databases.\n",
    "   Nucleic acids research. 2015 Jan 28;43(D1):D423-31.\n",
    "   doi:10.1093/nar/gku1161\n",
    "\n",
    "\n",
    "3. H2 data must be curated from UniProt:\n",
    "\n",
    "\n",
    "   | Allele | UniProt_Accession_ID | FASTA_URL                                    |\n",
    "   |--------|----------------------|----------------------------------------------|\n",
    "   | H2-Db  | P01899               | https://www.uniprot.org/uniprot/P01899.fasta |\n",
    "   | H2-Dd  | P01900               | https://www.uniprot.org/uniprot/P01900.fasta |\n",
    "   | H2-Dp  | P14427               | https://www.uniprot.org/uniprot/P14427.fasta |\n",
    "   | H2-Dk  | P14426               | https://www.uniprot.org/uniprot/P14426.fasta |\n",
    "   | H2-Dq  | Q31145               | https://www.uniprot.org/uniprot/Q31145.fasta |\n",
    "   | H2-Kb  | P01901               | https://www.uniprot.org/uniprot/P01901.fasta |\n",
    "   | H2-Kd  | P01902               | https://www.uniprot.org/uniprot/P01902.fasta |\n",
    "   | H2-Kk  | P04223               | https://www.uniprot.org/uniprot/P04223.fasta |\n",
    "   | H2-Kq  | P14428               | https://www.uniprot.org/uniprot/P14428.fasta |\n",
    "   | H2-Ld  | P01897               | https://www.uniprot.org/uniprot/P01897.fasta |\n",
    "   | H2-Lq  | Q31151               | https://www.uniprot.org/uniprot/Q31151.fasta |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0f14ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "datadir = os.path.join(os.pardir, \"data\")\n",
    "seqdir = os.path.join(datadir, \"seq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75429265",
   "metadata": {},
   "source": [
    "#### Compile all MHC sequences into a single FASTA file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4344f9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate a mapping from MHC allele to variable-length MHC protein sequence.\n",
    "The mappings are saved to compiled.fasta in the seq dir\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "def getMappings(fp, prefix=\"\"):\n",
    "    \"\"\"\n",
    "    Read FASTA file at location fp to extract allele-protein mappings.\n",
    "    FASTA description lines should be white-space separated such that\n",
    "    the second token is the MHC allele name. If only one token exists,\n",
    "    then the sole token is threated as the MHC allele name.\n",
    "    MHC proteins can span multiple lines.\n",
    "    \"\"\"\n",
    "    maps = dict()\n",
    "    with open(fp, 'r') as f:\n",
    "        allele = None\n",
    "        for line in [x.strip() for x in f.readlines()]:\n",
    "            if line.startswith('>'):\n",
    "                if allele is not None:\n",
    "                    maps[allele] = seq\n",
    "                toks = line.split()\n",
    "                name = toks[1] if len(toks) > 1 else toks[0][1:]\n",
    "                allele = prefix + name\n",
    "                seq = str()\n",
    "            else:\n",
    "                seq += line\n",
    "    return maps\n",
    "\n",
    "\n",
    "def extractSupertypes(rawmaps):\n",
    "    \"\"\"\n",
    "    Only supertypes are mapped (e.g. HLA-A\\*02:01 instead of HLA-A\\*02:01:01:02N).\n",
    "    If multiple sequences under a single supertype are received, then the\n",
    "    most frequent MHC protein sequence is selected. Ties are broken by choosing\n",
    "    the longer sequence to preserve as much information as possible.\n",
    "    Alleles with \"-N\" in the name are excluded such as Eqca-N*001:01 and BoLA-NC1*002:01.\n",
    "    \"\"\"\n",
    "    supmaps = dict()\n",
    "    supreg  = r\"[^:]+:[^:]+\"\n",
    "    for mhc,seq in rawmaps.items():\n",
    "        match = re.match(supreg, mhc)\n",
    "        if match is None:\n",
    "            continue\n",
    "        if \"-N\" in mhc:\n",
    "            continue\n",
    "        supmhc = match.group()\n",
    "        if supmhc not in supmaps:\n",
    "            supmaps[supmhc] = {seq:0}\n",
    "        else:\n",
    "            if seq in supmaps[supmhc]:\n",
    "                supmaps[supmhc][seq] += 1\n",
    "            else:\n",
    "                supmaps[supmhc][seq] = 0\n",
    "    maxmaps = dict()\n",
    "    for mhc,seqdict in supmaps.items():\n",
    "        maxcnt = 0\n",
    "        maxseq = str()\n",
    "        for seq,cnt in seqdict.items():\n",
    "            if cnt > maxcnt or (cnt==maxcnt and len(seq) > len(maxseq)):\n",
    "                maxcnt = cnt\n",
    "                maxseq = seq\n",
    "        supmaps[mhc] = maxseq\n",
    "        maxmaps[mhc] = maxseq\n",
    "    return maxmaps\n",
    "\n",
    "\n",
    "def filterClass(rawmaps):\n",
    "    \"\"\"\n",
    "    Extracts MHC-I molecules and stores them in dicts.\n",
    "    Valid alleles either start with H2 or end in a digit.\n",
    "    All MHC-II alleles contain \"-D\", and the rest are MHC-I.\n",
    "    \"\"\"\n",
    "    mhcmaps = dict()\n",
    "    for mhc,seq in rawmaps.items():\n",
    "        if \"-MIC\" in mhc:\n",
    "            continue\n",
    "        if \"-TAP\" in mhc:\n",
    "            continue\n",
    "        if \"-D\" in mhc:\n",
    "            continue\n",
    "        if (not mhc.startswith(\"H2\")) and mhc[-1].isalpha():\n",
    "            continue\n",
    "        mhcmaps[mhc] = seq\n",
    "    return mhcmaps\n",
    "\n",
    "\n",
    "def writemaps(fp, maps):\n",
    "    lines = [\">{}\\n{}\".format(k,v) for k,v in maps.items()]\n",
    "    lines.sort()\n",
    "    with open(fp, 'w') as f:\n",
    "        f.writelines('\\n'.join(lines))\n",
    "\n",
    "\n",
    "maps = dict()\n",
    "maps.update(getMappings(os.path.join(seqdir, \"hla.fasta\"), prefix=\"HLA-\"))\n",
    "maps.update(getMappings(os.path.join(seqdir, \"mhc.fasta\")))\n",
    "maps = extractSupertypes(maps)\n",
    "maps = filterClass(maps)\n",
    "maps.update(getMappings(os.path.join(seqdir, \"h2.fasta\")))\n",
    "print(\"writing compiled fasta with {} lines...\".format(len(maps)), end=\"\")\n",
    "writemaps(os.path.join(seqdir, \"compiled.fasta\"),  maps)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db623143",
   "metadata": {},
   "source": [
    "#### Align the compiled FASTA file and extract pseudosequences\n",
    "\n",
    "Each pseudosequence is designed to be a shortened representation of the amino acid residues in an MHC allele, which requires identifying the most important residue positions. The BigMHC approach uses a multiple sequence alignment (MSA) and calculates the relative entropy of each residue position when aligned to a set of MHC alleles. We consider the positions with the largest relative entropy to have the most information, from which we select the 30 most entropic positions. These calculations were performed using SAM suite 3.5.\n",
    "\n",
    "First, run SAM's `buildmodel` on a fasta file of unaligned sequences, such as the `compiled.fasta` file in the seq dir. You can use any set of unaligned sequences that you believe are relevant. `buildmodel` will generate a hidden Markov model of your sequences, after which you can construct an MSA using `align2model`, make a pretty alignment using `prettyalign`, and extract relative entropies for all positions using `makelogo`. This is our current method of computing pseudosequences, and although imprecision may arise, the resulting pseudosequences are comparable to the original implementation.\n",
    "\n",
    "Specifically, perform the following:\n",
    "1. Download the SAM source code: `wget https://karchinlab.org/datasets/sam-src.tar.gz`\n",
    "2. Extract the contents: `tar -xzvf sam-src.tar.gz`\n",
    "3. Within the SAM directory, configure the build: `./configure`\n",
    "4. Compile with GNU Make: `make`\n",
    "5. The executables are deposited in the SAM `src` directory, in which you can run the following commands:\n",
    "6. `./buildmodel mhc -train <PATH_TO_FASTA>`\n",
    "7. `./align2model mhc -modelfile mhc.mod -db <PATH_TO_FASTA>`\n",
    "8. `./prettyalign mhc.a2m -m0 > mhc.pretty`\n",
    "9. `./makelogo mhc -i mhc.mod &> mhc.bits`\n",
    "\n",
    "Note: the authors of SAM no longer develop or maintain the package; the contact information included in the package is obsolete, and we cannot provide any support for SAM installation or usage ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ae71de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Extract pseudo-sequences from SAM prettyalign output.\n",
    "\n",
    "Deletions are first replaced with dummy residue 'X'.\n",
    "Then, pseudosequences are extracted by taking the top n\n",
    "positions, sorted by entropy, where n is parameterized.\n",
    "\n",
    "The extracted components are onehot encoded before\n",
    "the resulting pseudosequences are saved to a csv file.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def extractPseudoseqs(inp):\n",
    "    aligns = dict()\n",
    "    with open(inp, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            if (line[0].isalpha() or line[0].isdigit()) and ' ' in line:\n",
    "                mhc = line[:line.find(' ')].strip()\n",
    "                seq = list(line[line.find(' '):].strip().replace('-','X'))\n",
    "                if mhc not in aligns:\n",
    "                    aligns[mhc] = seq\n",
    "                else:\n",
    "                    aligns[mhc] += seq\n",
    "    return pd.DataFrame.from_dict(aligns, orient=\"index\")\n",
    "\n",
    "\n",
    "def encodePseudoseqs(seqs, bits, cmps):\n",
    "    with open(bits, 'r') as f:\n",
    "        bit = [float(x.strip()) for x in f.readlines() if x[0].isdigit()]\n",
    "    rmi = [seqs.iloc[:,x].unique().shape[0]==1 for x in range(seqs.shape[1])]\n",
    "    idx = [x for x in range(len(rmi)) if not rmi[x]]\n",
    "    bit = [bit[x] for x in range(len(bit)) if not rmi[x]]\n",
    "    seqs.drop(seqs.columns[[x for x in range(seqs.shape[1]) if rmi[x]]], axis=1, inplace=True)\n",
    "    srt = [x[0] for x in sorted(enumerate(bit), key=lambda x: x[1])]\n",
    "    for x in srt[:cmps]:\n",
    "        print(\"{}\\t{}\".format(idx[x], ','.join(seqs.iloc[:,x].value_counts(ascending=False).index.values)))\n",
    "    seqs.drop(seqs.columns[srt[cmps:]], axis=1, inplace=True)\n",
    "    seqs = pd.get_dummies(seqs, drop_first=False, dtype=int)\n",
    "    print(\"dimensionality: {}\".format(seqs.shape[1]))\n",
    "    return seqs\n",
    "\n",
    "seqs = extractPseudoseqs(os.path.join(seqdir, \"mhc.pretty\"))\n",
    "encs = encodePseudoseqs(seqs, os.path.join(seqdir, \"mhc.bits\"), 30)\n",
    "encs.to_csv(os.path.join(datadir, \"pseudoseqs.csv\"), index_label=\"mhc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
