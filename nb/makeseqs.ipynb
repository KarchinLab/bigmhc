{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e6aa510",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------\n",
    "\n",
    "Copyright 2023 Benjamin Alexander Albert \\[Karchin Lab\\]\n",
    "\n",
    "All Rights Reserved\n",
    "\n",
    "BigMHC Academic License\n",
    "\n",
    "makeseqs.ipynb\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "#### Generate MHC pseudosequences from FASTA files\n",
    "\n",
    "Create a dir, which we will call `data`\n",
    "  * Create a dir within `data` called `seq`\n",
    "    * Store all of the FASTA files and SAM alignment files the `seq` dir\n",
    "  * The final `pseudoseqs.csv`file will be placed in the `data` dir\n",
    "\n",
    "\n",
    "Three protein FASTA files are required as input:\n",
    "\n",
    "1. HLA FASTA file retrieved from: https://github.com/ANHIG/IMGTHLA\n",
    "   \n",
    "   Robinson J, Barker DJ, Georgiou X, Cooper MA, Flicek P, Marsh SG.\n",
    "   IPD-IMGT/HLA Database.\n",
    "   Nucleic acids research. 2020 Jan 8;48(D1):D948-55.\n",
    "   doi:10.1093/nar/gkz950\n",
    "\n",
    "   Robinson J, Malik A, Parham P, Bodmer JG, Marsh SG.\n",
    "   IMGT/HLA database: a sequence database for the human major histocompatibility complex.\n",
    "   Tissue antigens. 2000 Mar;55(3):280-7.\n",
    "   doi:10.1034/j.1399-0039.2000.550314.x\n",
    "\n",
    "   \n",
    "2. non-HLA MHC FASTA file retrieved from: https://github.com/ANHIG/IPDMHC\n",
    "\n",
    "   Robinson J, Halliwell JA, Hayhurst JD, Flicek P, Parham P, Marsh SG.\n",
    "   The IPD and IMGT/HLA database: allele variant databases.\n",
    "   Nucleic acids research. 2015 Jan 28;43(D1):D423-31.\n",
    "   doi:10.1093/nar/gku1161\n",
    "\n",
    "\n",
    "3. H2 data must be curated from UniProt:\n",
    "\n",
    "\n",
    "   | Allele | UniProt_Accession_ID | FASTA_URL                                    |\n",
    "   |--------|----------------------|----------------------------------------------|\n",
    "   | H2-Db  | P01899               | https://www.uniprot.org/uniprot/P01899.fasta |\n",
    "   | H2-Dd  | P01900               | https://www.uniprot.org/uniprot/P01900.fasta |\n",
    "   | H2-Dp  | P14427               | https://www.uniprot.org/uniprot/P14427.fasta |\n",
    "   | H2-Dk  | P14426               | https://www.uniprot.org/uniprot/P14426.fasta |\n",
    "   | H2-Dq  | Q31145               | https://www.uniprot.org/uniprot/Q31145.fasta |\n",
    "   | H2-Kb  | P01901               | https://www.uniprot.org/uniprot/P01901.fasta |\n",
    "   | H2-Kd  | P01902               | https://www.uniprot.org/uniprot/P01902.fasta |\n",
    "   | H2-Kk  | P04223               | https://www.uniprot.org/uniprot/P04223.fasta |\n",
    "   | H2-Kq  | P14428               | https://www.uniprot.org/uniprot/P14428.fasta |\n",
    "   | H2-Ld  | P01897               | https://www.uniprot.org/uniprot/P01897.fasta |\n",
    "   | H2-Lq  | Q31151               | https://www.uniprot.org/uniprot/Q31151.fasta |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e0f14ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "datadir = os.path.join(os.pardir, \"data\")\n",
    "seqdir = os.path.join(datadir, \"seq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75429265",
   "metadata": {},
   "source": [
    "#### Compile all MHC sequences into a single FASTA file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4344f9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing compiled fasta with 18929 lines...done\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Generate a mapping from MHC allele to variable-length MHC protein sequence.\n",
    "The mappings are saved to compiled.fasta in the seq dir\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "def getMappings(fp, prefix=\"\"):\n",
    "    \"\"\"\n",
    "    Read FASTA file at location fp to extract allele-protein mappings.\n",
    "    FASTA description lines should be white-space separated such that\n",
    "    the second token is the MHC allele name. If only one token exists,\n",
    "    then the sole token is threated as the MHC allele name.\n",
    "    MHC proteins can span multiple lines.\n",
    "    \"\"\"\n",
    "    maps = dict()\n",
    "    with open(fp, 'r') as f:\n",
    "        allele = None\n",
    "        for line in [x.strip() for x in f.readlines()]:\n",
    "            if line.startswith('>'):\n",
    "                if allele is not None:\n",
    "                    maps[allele] = seq\n",
    "                toks = line.split()\n",
    "                name = toks[1] if len(toks) > 1 else toks[0][1:]\n",
    "                allele = prefix + name\n",
    "                seq = str()\n",
    "            else:\n",
    "                seq += line\n",
    "    return maps\n",
    "\n",
    "\n",
    "def extractSupertypes(rawmaps):\n",
    "    \"\"\"\n",
    "    Only supertypes are mapped (e.g. HLA-A\\*02:01 instead of HLA-A\\*02:01:01:02N).\n",
    "    If multiple sequences under a single supertype are received, then the\n",
    "    most frequent MHC protein sequence is selected. Ties are broken by choosing\n",
    "    the longer sequence to preserve as much information as possible.\n",
    "    Alleles with \"-N\" in the name are excluded such as Eqca-N*001:01 and BoLA-NC1*002:01.\n",
    "    \"\"\"\n",
    "    supmaps = dict()\n",
    "    supreg  = r\"[^:]+:[^:]+\"\n",
    "    for mhc,seq in rawmaps.items():\n",
    "        match = re.match(supreg, mhc)\n",
    "        if match is None:\n",
    "            continue\n",
    "        if \"-N\" in mhc:\n",
    "            continue\n",
    "        supmhc = match.group()\n",
    "        if supmhc not in supmaps:\n",
    "            supmaps[supmhc] = {seq:0}\n",
    "        else:\n",
    "            if seq in supmaps[supmhc]:\n",
    "                supmaps[supmhc][seq] += 1\n",
    "            else:\n",
    "                supmaps[supmhc][seq] = 0\n",
    "    maxmaps = dict()\n",
    "    for mhc,seqdict in supmaps.items():\n",
    "        maxcnt = 0\n",
    "        maxseq = str()\n",
    "        for seq,cnt in seqdict.items():\n",
    "            if cnt > maxcnt or (cnt==maxcnt and len(seq) > len(maxseq)):\n",
    "                maxcnt = cnt\n",
    "                maxseq = seq\n",
    "        supmaps[mhc] = maxseq\n",
    "        maxmaps[mhc] = maxseq\n",
    "    return maxmaps\n",
    "\n",
    "\n",
    "def filterClass(rawmaps):\n",
    "    \"\"\"\n",
    "    Extracts MHC-I molecules and stores them in dicts.\n",
    "    Valid alleles either start with H2 or end in a digit.\n",
    "    All MHC-II alleles contain \"-D\", and the rest are MHC-I.\n",
    "    \"\"\"\n",
    "    mhcmaps = dict()\n",
    "    for mhc,seq in rawmaps.items():\n",
    "        if \"-MIC\" in mhc:\n",
    "            continue\n",
    "        if \"-TAP\" in mhc:\n",
    "            continue\n",
    "        if \"-D\" in mhc:\n",
    "            continue\n",
    "        if (not mhc.startswith(\"H2\")) and mhc[-1].isalpha():\n",
    "            continue\n",
    "        mhcmaps[mhc] = seq\n",
    "    return mhcmaps\n",
    "\n",
    "\n",
    "def writemaps(fp, maps):\n",
    "    lines = [\">{}\\n{}\".format(k,v) for k,v in maps.items()]\n",
    "    lines.sort()\n",
    "    with open(fp, 'w') as f:\n",
    "        f.writelines('\\n'.join(lines))\n",
    "\n",
    "\n",
    "maps = dict()\n",
    "maps.update(getMappings(os.path.join(seqdir, \"hla.fasta\"), prefix=\"HLA-\"))\n",
    "maps.update(getMappings(os.path.join(seqdir, \"mhc.fasta\")))\n",
    "maps = extractSupertypes(maps)\n",
    "maps = filterClass(maps)\n",
    "maps.update(getMappings(os.path.join(seqdir, \"h2.fasta\")))\n",
    "print(\"writing compiled fasta with {} lines...\".format(len(maps)), end=\"\")\n",
    "writemaps(os.path.join(seqdir, \"compiled.fasta\"),  maps)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db623143",
   "metadata": {},
   "source": [
    "#### Align the compiled FASTA file\n",
    "Run SAM suite 3.5 buildmodel and align2model with default parameters on the `compiled.fasta` file in the seq dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0ae71de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\tY,V,S,A,M,F,C,X,T,I,L,G,H,D,P,Q,N\n",
      "138\tD,N,H,R,E,Q,Y,S,X,W,M,G,C,T,F,L,V,K,I,P\n",
      "180\tL,W,R,Q,D,M,F,H,X,V,I,E,K,Y,G,S,P,T,C,N,A\n",
      "48\tA,S,T,E,Y,X,V,I,D,P,G,F,N,L,Q\n",
      "187\tT,E,L,R,X,P,K,Q,G,A,M,V,W,S,N,D\n",
      "121\tR,W,T,M,I,S,K,V,N,X,G,L,E,A,Q,D,P\n",
      "93\tA,T,R,G,D,E,X,V,N,S,Q,H,C,I,L,P\n",
      "95\tA,T,S,X,E,V,P,L,K\n",
      "140\tY,S,D,F,L,H,X,Q,R,V,E,I,T,C,M,N,A,G,P\n",
      "176\tV,E,A,Y,W,X,T,D,R,G,N,L,S,H,K,Q,M,F,P\n",
      "2\tX,R,A,L,Q,P,T,G,W,K,M\n",
      "319\tX,A,G,V\n",
      "119\tL,I,V,W,F,Y,X,R,M,A,P,N,T,G,H\n",
      "33\tY,S,H,F,D,T,G,X,L,I,R,N,E,C,A,V,Q,K,P\n",
      "101\tN,S,D,G,A,X,C,T,K,Y,R,I,W,H\n",
      "320\tX,V,A,T,S,L,I,F\n",
      "94\tQ,N,H,A,T,S,R,E,D,K,X,I,F,V,L,C,Y,G,P,W\n",
      "316\tA,X,V,I,G,L,T,D,F\n",
      "317\tX,V,L,I,G,A,F,T,H\n",
      "35\tA,S,T,G,X,Y,V,C,F,L,N,D\n",
      "100\tV,E,A,G,X,M,R,L,K,D,S,Q,P,I\n",
      "105\tL,A,X,V,I,Q,P,T,M,G,R,E,S\n",
      "86\tR,E,Q,G,L,X,P,S,W,D,K,H,V,M,A\n",
      "9\tL,X,V,F,H,P,I,R,T\n",
      "339\tX,G,R,E,A,K,V,Q\n",
      "206\tA,T,X,L,S,V,E,P,M,R,G,Q,C,K\n",
      "329\tA,X,V,T,F,I,S,P\n",
      "10\tL,X,I,V,F,A,P,M,R,T,H\n",
      "182\tA,T,V,N,X,S,G,P,Q,I,K,D,F\n",
      "90\tI,K,N,R,L,S,X,T,Y,V,G,H,F,D,M,Q,A,E,P\n",
      "dimensionality: 414\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Extract pseudo-sequences from SAM prettyalign output.\n",
    "\n",
    "Deletions are first replaced with dummy residue 'X'.\n",
    "Then, pseudosequences are extracted by taking the top n\n",
    "positions, sorted by entropy, where n is parameterized.\n",
    "\n",
    "The extracted components are onehot encoded before\n",
    "the resulting pseudosequences are saved to a csv file.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def extractPseudoseqs(inp):\n",
    "    aligns = dict()\n",
    "    with open(inp, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            if (line[0].isalpha() or line[0].isdigit()) and ' ' in line:\n",
    "                mhc = line[:line.find(' ')].strip()\n",
    "                seq = list(line[line.find(' '):].strip().replace('-','X'))\n",
    "                if mhc not in aligns:\n",
    "                    aligns[mhc] = seq\n",
    "                else:\n",
    "                    aligns[mhc] += seq\n",
    "    return pd.DataFrame.from_dict(aligns, orient=\"index\")\n",
    "\n",
    "\n",
    "def encodePseudoseqs(seqs, bits, cmps):\n",
    "    with open(bits, 'r') as f:\n",
    "        bit = [float(x.strip()) for x in f.readlines() if x[0].isdigit()]\n",
    "    rmi = [seqs.iloc[:,x].unique().shape[0]==1 for x in range(seqs.shape[1])]\n",
    "    idx = [x for x in range(len(rmi)) if not rmi[x]]\n",
    "    bit = [bit[x] for x in range(len(bit)) if not rmi[x]]\n",
    "    seqs.drop(seqs.columns[[x for x in range(seqs.shape[1]) if rmi[x]]], axis=1, inplace=True)\n",
    "    srt = [x[0] for x in sorted(enumerate(bit), key=lambda x: x[1])]\n",
    "    for x in srt[:cmps]:\n",
    "        print(\"{}\\t{}\".format(idx[x], ','.join(seqs.iloc[:,x].value_counts(ascending=False).index.values)))\n",
    "    seqs.drop(seqs.columns[srt[cmps:]], axis=1, inplace=True)\n",
    "    seqs = pd.get_dummies(seqs, drop_first=False)\n",
    "    print(\"dimensionality: {}\".format(seqs.shape[1]))\n",
    "    return seqs\n",
    "\n",
    "seqs = extractPseudoseqs(os.path.join(seqdir, \"mhc.pretty\"))\n",
    "encs = encodePseudoseqs(seqs, os.path.join(seqdir, \"mhc.bits\"), 30)\n",
    "encs.to_csv(os.path.join(datadir, \"pseudoseqs.csv\"), index_label=\"mhc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
