{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec730cd0",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------\n",
    "\n",
    "Copyright 2023 Benjamin Alexander Albert \\[Karchin Lab\\]\n",
    "\n",
    "All Rights Reserved\n",
    "\n",
    "BigMHC Academic License\n",
    "\n",
    "runothers.ipynb\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "#### Run Other Methods for Comparison Against BigMHC\n",
    "\n",
    "Create a dir, which we will call `third_party`\n",
    " * Store all of the below downloadables will be placed in `third_party`\n",
    " * All results will be placed in a dir called `out` within the `third_party`\n",
    "\n",
    "Install **NetMHCpan-4.1** https://services.healthtech.dtu.dk/service.php?NetMHCpan-4.1\n",
    "  * Download NetMHCpan-4.1b and extract all contents to a dir called netmhcpan\n",
    "    * the directory structure should be `third_party/netmhcpan/ where netmhcpan contains:\n",
    "      * Linux_x86_64 dir\n",
    "      * netMHCpan tcsh script\n",
    "      * netMHCpan.1 file\n",
    "      * netMHCpan-4.1.readme\n",
    "      * test dir\n",
    "  * Follow the instructions of the netmhcpan-4.1.readme to install and test NetMHCpan-4.1\n",
    "    * The instructions are summarized below for completeness:\n",
    "      * `wget https://services.healthtech.dtu.dk/services/NetMHCpan-4.1/data.tar.gz`\n",
    "      * `tar -xvf data.tar.gz`\n",
    "      * `rm data.tar.gz`\n",
    "      * Edit the `netMHCpan` script and replace the default NMHOME var with the full path to the `netmhcpan` dir\n",
    "      * From within the `netmhcpan`/test dir, run the following:\n",
    "        * ../netMHCpan -p test.pep > test.pep.myout\n",
    "        * ../netMHCpan test.fsa > test.fsa.myout\n",
    "        * ../netMHCpan -hlaseq B0702.fsa -p test.pep > test.pep_userMHC.myout\n",
    "        * ../netMHCpan -p test.pep -BA -xls -a HLA-A01:01,HLA-A02:01 -xlsfile NetMHCpan_myout.xls\n",
    "      * Then diff each of the `.myout` files with their respective `.out` files:\n",
    "        * diff test.pep.out test.pep.myout\n",
    "        * diff test.fsa.out test.fsa.myout\n",
    "        * diff test.pep_userMHC.out test.pep_userMHC.myout\n",
    "        * diff NetMHCpan_out.xls NetMHCpan_myout.xls\n",
    "\n",
    "Install **MHCflurry-2.0** https://github.com/openvax/mhcflurry\n",
    "  * `conda install tensorflow` or `pip install tensorflow` version 2.2.0 or later\n",
    "  * `pip install mhcflurry`\n",
    "  * `mhcflurry-downloads fetch`\n",
    "\n",
    "Install **MHCnuggets** https://github.com/KarchinLab/mhcnuggets\n",
    "  * `git clone https://github.com/KarchinLab/mhcnuggets.git`\n",
    "  * Refactor all imports `from mhcnuggets.src.X` to `from X`. Within the src dir, run:\n",
    "    * `sed -i \"s/from mhcnuggets.src./from /g\" *.py`\n",
    "\n",
    "Install **TransPHLA** https://github.com/a96123155/TransPHLA-AOMP\n",
    "  * `git clone https://github.com/a96123155/TransPHLA-AOMP.git`\n",
    "  * We need to remove the sigmoidal activation to prevent output values from being squashed to 0 or 1\n",
    "    * In the `model.py` file found in `TransPHLA-AOMP/TransPHLA-AOMP`, within the `eval_step` function, do the following:\n",
    "      * Replace: `y_prob_val = nn.Softmax(dim = 1)(val_outputs)[:, 1].cpu().detach().numpy()`\n",
    "      * With: `y_prob_val = val_outputs[:, 1].cpu().detach().numpy()`\n",
    "  * On line 99 of TransPHLA-AOMP/TransPHLA-AOMP/pHLAIformer.py, there is an erroneous indentation\n",
    "    * Remove a single tab in front of `log = Logger(errLogPath)`\n",
    "  * On lines 63-65 of TransPHLA-AOMP/TransPHLA-AOMP/pHLAIformer.py, change the argument type from `bool` to `int`\n",
    "    * As of November 27, 2022, Argparse does not support setting argument type `bool`\n",
    "  * To enable CUDA, set `use_cuda = True` on each of the following lines:\n",
    "    * line 160 of TransPHLA-AOMP/TransPHLA-AOMP/pHLAIformer.py\n",
    "    * line 62 of TransPHLA-AOMP/TransPHLA-AOMP/model.py\n",
    "\n",
    "Install **MixMHCpred2.1** and **MixMHCpred2.2** https://github.com/GfellerLab/MixMHCpred/releases\n",
    "  * Download and extract MixMHCpred v2.1 and v2.2\n",
    "    * `wget https://github.com/GfellerLab/MixMHCpred/archive/refs/tags/v2.1.tar.gz`\n",
    "    * `wget https://github.com/GfellerLab/MixMHCpred/archive/refs/tags/v2.2.tar.gz`\n",
    "    * `tar -xzvf v2.1.tar.gz`\n",
    "    * `tar -xzvf v2.2.tar.gz`\n",
    "    * `rm v2.1.tar.gz v2.1.tar.gz`\n",
    "  * Compile the models\n",
    "    * `g++ -O3 MixMHCpred-2.1/lib/MixMHCpred.cc -o MixMHCpred-2.1/lib/MixMHCpred.x`\n",
    "    * `g++ -O3 MixMHCpred-2.2/lib/MixMHCpred.cc -o MixMHCpred-2.2/lib/MixMHCpred.x`\n",
    "  * Edit the `MixMHCpred` scripts and set the lib_path var to the full path of MixMHCpred-2.x/lib\n",
    "  * Test the installation from within each of the MixMHCpred-2.x dirs:\n",
    "    * `./MixMHCpred -i test/test.fa -o test/out.txt -a A0101,A2501,B0801,B1801`\n",
    "    * `diff test/out_compare.txt test/out.txt`\n",
    "\n",
    "Install **PRIME-1.0** and **PRIME-2.0** https://github.com/GfellerLab/PRIME/releases\n",
    "  * Download and extract PRIME v1.0 and v2.0:\n",
    "    * `wget https://github.com/GfellerLab/PRIME/archive/refs/tags/v1.0.tar.gz`\n",
    "    * `wget https://github.com/GfellerLab/PRIME/archive/refs/tags/v2.0.tar.gz`\n",
    "    * `tar -xzvf v1.0.tar.gz`\n",
    "    * `tar -xzvf v2.0.tar.gz`\n",
    "    * `rm v1.0.tar.gz v2.0.tar.gz`\n",
    "  * Compile PRIME-2.0 (version 1.0 does not need compilation)\n",
    "    * `g++ -O3 PRIME-2.0/lib/PRIME.cc -o PRIME-2.0/lib/PRIME.x`\n",
    "  * Edit the `PRIME` scripts and set the lib_path var to the full path of PRIME-1.x/lib\n",
    "  * Test the installation from within each of the PRIME-1.x dirs\n",
    "    * Test PRIME-1.0\n",
    "      * `./PRIME -i test/test.txt -o test/out.txt -a A0201,A0101 -mix MixMHCpred2.1_path`\n",
    "      * `diff test/out_compare.txt test/out.txt`\n",
    "    * Test PRIME-2.0\n",
    "      * `./PRIME -i test/test.txt -o test/out.txt -a A0101,A2501,B0801,B1801 -mix MixMHCpred2.2_path`\n",
    "      * `diff test/out_compare.txt test/out.txt`\n",
    "\n",
    "Install **HLAthena** http://hlathena.tools/\n",
    "  * Install Docker https://docs.docker.com/\n",
    "    * Debian installation instructions: https://docs.docker.com/desktop/install/debian/\n",
    "  * If on Linux, add your user to the docker group\n",
    "    * `sudo usermod -aG docker $USER`\n",
    "  * Pull the HLAthena docker image:\n",
    "    * `docker pull ssarkizova/hlathena-external`\n",
    "  * To kill all instances of HLAthena, run the following:\n",
    "    * `docker stop $(docker ps -q --filter ancestor=ssarkizova/hlathena-external)`\n",
    "    * This will complain if no containers are running\n",
    "  \n",
    "------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09d2fdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "datadir = os.path.abspath(\"../data\")\n",
    "outdir = os.path.join(datadir, \"out\")\n",
    "prddir = os.path.join(datadir, \"prd\")\n",
    "\n",
    "verbose = False\n",
    "\n",
    "ranks = True\n",
    "\n",
    "# HLAthena does not appear to like tmpdir being \"/tmp\"\n",
    "tmpdir = os.path.abspath(os.path.join(datadir, \"tmp\"))\n",
    "tmpfile = os.path.abspath(os.path.join(tmpdir, \"tmp.csv\"))\n",
    "\n",
    "thirdparty = os.path.abspath(\"../third_party\")\n",
    "pseudofile = os.path.join(thirdparty, \"netmhcpan/data/MHC_pseudo.dat\")\n",
    "\n",
    "gid = os.popen(\"id -g $USER\").read()\n",
    "\n",
    "if not os.path.exists(tmpdir):\n",
    "    os.makedirs(tmpdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31705421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def uid(df):\n",
    "    df[\"uid\"] = df[\"mhc\"] + '_' + df[\"pep\"]\n",
    "    return df.set_index(\"uid\", drop=True)\n",
    "\n",
    "\n",
    "def subprocrun(cmd, cwd=None, pipe=(not verbose)):\n",
    "    if pipe:\n",
    "        res = subprocess.run(\n",
    "            cmd.split(),\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            universal_newlines=True,\n",
    "            cwd=cwd)\n",
    "    else:\n",
    "        res = subprocess.run(\n",
    "            cmd.split(),\n",
    "            universal_newlines=True,\n",
    "            cwd=cwd)\n",
    "    return res.stdout\n",
    "\n",
    "\n",
    "def runmodel(func, data, name):\n",
    "    out = list()\n",
    "    for mhc, grp in data.groupby(\"mhc\"):\n",
    "        out.append(pd.Series(\n",
    "            data=func(mhc, grp[\"pep\"]),\n",
    "            index=grp.index,\n",
    "            name=name))\n",
    "        try:\n",
    "            os.remove(tmpfile)\n",
    "        except OSError:\n",
    "            pass\n",
    "    return pd.concat(out)\n",
    "\n",
    "\n",
    "def mhcnuggets(data, outfile):\n",
    "\n",
    "    def _run(mhc, pep):\n",
    "        pep.to_csv(\n",
    "            tmpfile,\n",
    "            header=False,\n",
    "            index=False)\n",
    "        cmd = \"python predict.py\" + \\\n",
    "            \" --class=I\" + \\\n",
    "            \" --peptides={}\".format(tmpfile) + \\\n",
    "            \" --allele={}\".format(mhc.replace('*','')) + \\\n",
    "            \" --output={}\".format(outfile)\n",
    "        subprocrun(\n",
    "            cmd=cmd,\n",
    "            cwd=os.path.join(thirdparty, \"mhcnuggets/mhcnuggets/src\"))\n",
    "        ic50 = pd.read_csv(\n",
    "            outfile,\n",
    "            usecols=[\"ic50\"]).iloc[:,0].tolist()\n",
    "        return 1 - (np.log(ic50) / np.log(50000))\n",
    "\n",
    "    return runmodel(\n",
    "        func=_run,\n",
    "        data=data,\n",
    "        name=\"MHCnuggets-2.4.0\")\n",
    "\n",
    "\n",
    "def netmhcpan(data, outfile):\n",
    "\n",
    "    def _run(mhc, pep):\n",
    "        pep.to_csv(\n",
    "            tmpfile,\n",
    "            header=False,\n",
    "            index=False)\n",
    "        cmd = \"./netMHCpan\" + \\\n",
    "            \" -p {}\".format(tmpfile) + \\\n",
    "            \" -a {}\".format(mhc.replace('*','')) + \\\n",
    "            \" -xls\" + \\\n",
    "            \" -xlsfile {}\".format(outfile)\n",
    "        subprocrun(\n",
    "            cmd=cmd,\n",
    "            cwd=os.path.join(thirdparty, \"netmhcpan\"))\n",
    "        return pd.read_csv(\n",
    "            outfile,\n",
    "            delimiter='\\t',\n",
    "            skiprows=1,\n",
    "            usecols=[\"EL_Rank\" if ranks else \"EL-score\"]).iloc[:,0].tolist()\n",
    "\n",
    "    return runmodel(\n",
    "        func=_run,\n",
    "        data=data,\n",
    "        name=\"NetMHCpan-4.1\")\n",
    "\n",
    "\n",
    "def hlathena(data, outfile):\n",
    "    def _run(mhc, pep):\n",
    "        pep.to_csv(\n",
    "            tmpfile,\n",
    "            index=False)\n",
    "        cmd = \"docker run --user 0:{} \".format(gid) + \\\n",
    "            \" -v {}:{}\".format(tmpdir, tmpdir) + \\\n",
    "            \" -w {}\".format(tmpdir) + \\\n",
    "            \" ssarkizova/hlathena-external predict\" + \\\n",
    "            \" --runID hlathena\" + \\\n",
    "            \" --rundir {}\".format(tmpdir) + \\\n",
    "            \" -p {}\".format(tmpfile) + \\\n",
    "            \" -a {}\".format(mhc[4:].replace('*','').replace(':',''))\n",
    "        subprocrun(\n",
    "            cmd=cmd,\n",
    "            cwd=tmpdir)\n",
    "        prd = pd.read_csv(\n",
    "            os.path.join(tmpdir, \"hlathena-predictions.txt\"),\n",
    "            delimiter='\\t',\n",
    "            usecols=[0,4 if ranks else 3])\n",
    "        return prd.set_index(\"pep\").loc[pep].iloc[:,0].tolist()\n",
    "\n",
    "    return runmodel(\n",
    "        func=_run,\n",
    "        data=data,\n",
    "        name=\"HLAthena\")\n",
    "\n",
    "\n",
    "def _gfeller(method, data, outfile):\n",
    "\n",
    "    def _run(mhc, pep):\n",
    "        pep.to_csv(\n",
    "            tmpfile,\n",
    "            header=False,\n",
    "            index=False)\n",
    "        if method==\"PRIME-1.0\":\n",
    "            cmd = \"./PRIME -mix ../MixMHCpred-2.1/MixMHCpred\"\n",
    "            cwd = os.path.join(thirdparty, \"PRIME-1.0\")\n",
    "        elif method==\"PRIME-2.0\":\n",
    "            cmd = \"./PRIME -mix ../MixMHCpred-2.2/MixMHCpred\"\n",
    "            cwd = os.path.join(thirdparty, \"PRIME-2.0\")\n",
    "        elif method==\"MixMHCpred-2.1\":\n",
    "            cmd = \"./MixMHCpred\"\n",
    "            cwd = os.path.join(thirdparty, \"MixMHCpred-2.1\")\n",
    "        elif method==\"MixMHCpred-2.2\":\n",
    "            cmd = \"./MixMHCpred\"\n",
    "            cwd = os.path.join(thirdparty, \"MixMHCpred-2.2\")\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Unexpected gfeller method: {}\".format(method))\n",
    "        cmd += \\\n",
    "            \" -i {}\".format(tmpfile) + \\\n",
    "            \" -a {}\".format(mhc) + \\\n",
    "            \" -o {}\".format(outfile)\n",
    "        subprocrun(\n",
    "            cmd=cmd,\n",
    "            cwd=cwd)\n",
    "        try:\n",
    "            return pd.read_csv(\n",
    "                outfile,\n",
    "                delimiter='\\t',\n",
    "                skiprows=11,\n",
    "                usecols=[\"%Rank_bestAllele\" if ranks else \"Score_bestAllele\"]).iloc[:,0].tolist()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return [float(\"nan\") for _ in range(len(pep))]\n",
    "\n",
    "    return runmodel(\n",
    "        func=_run,\n",
    "        data=data,\n",
    "        name=method)\n",
    "\n",
    "\n",
    "def prime1(data, outfile):\n",
    "    return _gfeller(\"PRIME-1.0\", data, outfile)\n",
    "\n",
    "\n",
    "def prime2(data, outfile):\n",
    "    return _gfeller(\"PRIME-2.0\", data, outfile)\n",
    "\n",
    "\n",
    "def mixmhcpred21(data, outfile):\n",
    "    return _gfeller(\"MixMHCpred-2.1\", data, outfile)\n",
    "\n",
    "\n",
    "def mixmhcpred22(data, outfile):\n",
    "    return _gfeller(\"MixMHCpred-2.2\", data, outfile)\n",
    "\n",
    "\n",
    "def mhcflurry(data, outfile):\n",
    "    data.to_csv(\n",
    "        tmpfile,\n",
    "        columns=[\"mhc\",\"pep\"],\n",
    "        header=[\"allele\",\"peptide\"],\n",
    "        index=False)\n",
    "    cmd = \"mhcflurry-predict {} --out={}\".format(\n",
    "        tmpfile, outfile)\n",
    "    subprocrun(cmd=cmd)\n",
    "\n",
    "    out = pd.read_csv(\n",
    "        outfile,\n",
    "        usecols=[\"mhcflurry_presentation_percentile\" if ranks else \"mhcflurry_presentation_score\"]\n",
    "    ).iloc[:,0].tolist()\n",
    "\n",
    "    name = \"MHCflurry-2.0\"\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"mhc\":data[\"mhc\"],\n",
    "        \"pep\":data[\"pep\"],\n",
    "        name:out})\n",
    "\n",
    "    return uid(out)[name]\n",
    "\n",
    "\n",
    "def transphla(data, outfile):\n",
    "\n",
    "    chunksize = 100*1000\n",
    "\n",
    "    mhcmap = dict()\n",
    "    with open(pseudofile, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.strip()\n",
    "            mhc = line[:line.find(' ')]\n",
    "            seq = line[line.rfind(' ')+1:]\n",
    "            mhcmap[mhc] = seq\n",
    "\n",
    "    mhclines = [\n",
    "        \">{}\\n{}\".format(\n",
    "            mhc,\n",
    "            mhcmap[mhc.replace('*','')])\n",
    "        for mhc in data[\"mhc\"]]\n",
    "\n",
    "    peplines = [\n",
    "        \">{}\\n{}\".format(\n",
    "            pep,\n",
    "            pep)\n",
    "        for pep in data[\"pep\"]]\n",
    "\n",
    "    col = \"y_prob\"\n",
    "    idx1 = 0\n",
    "    preds = list()\n",
    "    while idx1 < len(data):\n",
    "        idx2 = min(idx1+chunksize, len(data))\n",
    "        with open(outfile, 'w') as f:\n",
    "            f.write('\\n'.join(mhclines[idx1:idx2]))\n",
    "        with open(tmpfile, 'w') as f:\n",
    "            f.write('\\n'.join(peplines[idx1:idx2]))\n",
    "        cmd = \"python pHLAIformer.py\" + \\\n",
    "            \" --peptide_file={}\".format(tmpfile) + \\\n",
    "            \" --HLA_file={}\".format(outfile) + \\\n",
    "            \" --cut_length=15\" + \\\n",
    "            \" --output_dir=/tmp\" + \\\n",
    "            \" --output_attention=0\" + \\\n",
    "            \" --output_heatmap=0\" + \\\n",
    "            \" --output_mutation=0\"\n",
    "        subprocrun(\n",
    "            cmd=cmd,\n",
    "            cwd=os.path.join(thirdparty, \"TransPHLA-AOMP/TransPHLA-AOMP\"))\n",
    "        preds.append(\n",
    "            pd.read_csv(\n",
    "                \"/tmp/predict_results.csv\",\n",
    "                usecols=[col]))\n",
    "        idx1 = idx2\n",
    "\n",
    "    out = pd.concat(preds)[col].tolist()\n",
    "\n",
    "    name = \"TransPHLA\"\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"mhc\":data[\"mhc\"],\n",
    "        \"pep\":data[\"pep\"],\n",
    "        name:out})\n",
    "\n",
    "    return uid(out)[name]\n",
    "\n",
    "\n",
    "def run(models, filename):\n",
    "    print(\"running {}...\".format(filename[:filename.index('.')]))\n",
    "    prdfile = os.path.join(prddir, filename)\n",
    "    df = uid(pd.read_csv(os.path.join(outdir, filename)))\n",
    "    for m in models:\n",
    "        start = time.time()\n",
    "        out = m(df, prdfile)\n",
    "        print(m.__name__, time.time() - start)\n",
    "        df = pd.concat((df, out), axis=1)\n",
    "    df.to_csv(prdfile, index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "16f7e5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = run([netmhcpan, mhcnuggets, mixmhcpred21, mixmhcpred22, transphla],\n",
    "    \"el_test.csv\")\n",
    "\n",
    "df = run([netmhcpan, mhcflurry, mhcnuggets, mixmhcpred21, mixmhcpred22, prime1, prime2, transphla, hlathena],\n",
    "    \"asdf.csv\")\n",
    "\n",
    "df = run([netmhcpan, mhcflurry, mhcnuggets, mixmhcpred21, mixmhcpred22, prime1, prime2, transphla, hlathena],\n",
    "    \"iedb.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
